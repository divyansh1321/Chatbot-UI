{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "31d9a4c9",
      "metadata": {
        "origin_pos": 0,
        "id": "31d9a4c9"
      },
      "source": [
        "# Using Jupyter Notebooks\n",
        ":label:`sec_jupyter`\n",
        "\n",
        "\n",
        "This section describes how to edit and run the code\n",
        "in each section of this book\n",
        "using the Jupyter Notebook. Make sure you have\n",
        "installed Jupyter and downloaded the\n",
        "code as described in\n",
        ":ref:`chap_installation`.\n",
        "If you want to know more about Jupyter see the excellent tutorial in\n",
        "their [documentation](https://jupyter.readthedocs.io/en/latest/).\n",
        "\n",
        "\n",
        "## Editing and Running the Code Locally\n",
        "\n",
        "Suppose that the local path of the book's code is `xx/yy/d2l-en/`. Use the shell to change the directory to this path (`cd xx/yy/d2l-en`) and run the command `jupyter notebook`. If your browser does not do this automatically, open http://localhost:8888 and you will see the interface of Jupyter and all the folders containing the code of the book, as shown in :numref:`fig_jupyter00`.\n",
        "\n",
        "![The folders containing the code of this book.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter00.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter00`\n",
        "\n",
        "\n",
        "You can access the notebook files by clicking on the folder displayed on the webpage.\n",
        "They usually have the suffix \".ipynb\".\n",
        "For the sake of brevity, we create a temporary \"test.ipynb\" file.\n",
        "The content displayed after you click it is\n",
        "shown in :numref:`fig_jupyter01`.\n",
        "This notebook includes a markdown cell and a code cell. The content in the markdown cell includes \"This Is a Title\" and \"This is text.\".\n",
        "The code cell contains two lines of Python code.\n",
        "\n",
        "![Markdown and code cells in the \"text.ipynb\" file.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter01.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter01`\n",
        "\n",
        "\n",
        "Double click on the markdown cell to enter edit mode.\n",
        "Add a new text string \"Hello world.\" at the end of the cell, as shown in :numref:`fig_jupyter02`.\n",
        "\n",
        "![Edit the markdown cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter02.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter02`\n",
        "\n",
        "\n",
        "As demonstrated in :numref:`fig_jupyter03`,\n",
        "click \"Cell\" $\\rightarrow$ \"Run Cells\" in the menu bar to run the edited cell.\n",
        "\n",
        "![Run the cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter03.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter03`\n",
        "\n",
        "After running, the markdown cell is shown in :numref:`fig_jupyter04`.\n",
        "\n",
        "![The markdown cell after running.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter04.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter04`\n",
        "\n",
        "\n",
        "Next, click on the code cell. Multiply the elements by 2 after the last line of code, as shown in :numref:`fig_jupyter05`.\n",
        "\n",
        "![Edit the code cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter05.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter05`\n",
        "\n",
        "\n",
        "You can also run the cell with a shortcut (\"Ctrl + Enter\" by default) and obtain the output result from :numref:`fig_jupyter06`.\n",
        "\n",
        "![Run the code cell to obtain the output.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter06.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter06`\n",
        "\n",
        "\n",
        "When a notebook contains more cells, we can click \"Kernel\" $\\rightarrow$ \"Restart & Run All\" in the menu bar to run all the cells in the entire notebook. By clicking \"Help\" $\\rightarrow$ \"Edit Keyboard Shortcuts\" in the menu bar, you can edit the shortcuts according to your preferences.\n",
        "\n",
        "## Advanced Options\n",
        "\n",
        "Beyond local editing two things are quite important: editing the notebooks in the markdown format and running Jupyter remotely.\n",
        "The latter matters when we want to run the code on a faster server.\n",
        "The former matters since Jupyter's native ipynb format stores a lot of auxiliary data that is\n",
        "irrelevant to the content,\n",
        "mostly related to how and where the code is run.\n",
        "This is confusing for Git, making\n",
        "reviewing contributions very difficult.\n",
        "Fortunately there is an alternative---native editing in the markdown format.\n",
        "\n",
        "### Markdown Files in Jupyter\n",
        "\n",
        "If you wish to contribute to the content of this book, you need to modify the\n",
        "source file (md file, not ipynb file) on GitHub.\n",
        "Using the notedown plugin we\n",
        "can modify notebooks in the md format directly in Jupyter.\n",
        "\n",
        "\n",
        "First, install the notedown plugin, run the Jupyter Notebook, and load the plugin:\n",
        "\n",
        "```\n",
        "pip install d2l-notedown  # You may need to uninstall the original notedown.\n",
        "jupyter notebook --NotebookApp.contents_manager_class='notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "You may also turn on the notedown plugin by default whenever you run the Jupyter Notebook.\n",
        "First, generate a Jupyter Notebook configuration file (if it has already been generated, you can skip this step).\n",
        "\n",
        "```\n",
        "jupyter notebook --generate-config\n",
        "```\n",
        "\n",
        "Then, add the following line to the end of the Jupyter Notebook configuration file (for Linux or macOS, usually in the path `~/.jupyter/jupyter_notebook_config.py`):\n",
        "\n",
        "```\n",
        "c.NotebookApp.contents_manager_class = 'notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "After that, you only need to run the `jupyter notebook` command to turn on the notedown plugin by default.\n",
        "\n",
        "### Running Jupyter Notebooks on a Remote Server\n",
        "\n",
        "Sometimes, you may want to run Jupyter notebooks on a remote server and access it through a browser on your local computer. If Linux or macOS is installed on your local machine (Windows can also support this function through third-party software such as PuTTY), you can use port forwarding:\n",
        "\n",
        "```\n",
        "ssh myserver -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "The above string `myserver` is the address of the remote server.\n",
        "Then we can use http://localhost:8888 to access the remote server `myserver` that runs Jupyter notebooks. We will detail on how to run Jupyter notebooks on AWS instances\n",
        "later in this appendix.\n",
        "\n",
        "### Timing\n",
        "\n",
        "We can use the `ExecuteTime` plugin to time the execution of each code cell in Jupyter notebooks.\n",
        "Use the following commands to install the plugin:\n",
        "\n",
        "```\n",
        "pip install jupyter_contrib_nbextensions\n",
        "jupyter contrib nbextension install --user\n",
        "jupyter nbextension enable execute_time/ExecuteTime\n",
        "```\n",
        "\n",
        "## Summary\n",
        "\n",
        "* Using the Jupyter Notebook tool, we can edit, run, and contribute to each section of the book.\n",
        "* We can run Jupyter notebooks on remote servers using port forwarding.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Edit and run the code in this book with the Jupyter Notebook on your local machine.\n",
        "1. Edit and run the code in this book with the Jupyter Notebook *remotely* via port forwarding.\n",
        "1. Compare the running time of the operations $\\mathbf{A}^\\top \\mathbf{B}$ and $\\mathbf{A} \\mathbf{B}$ for two square matrices in $\\mathbb{R}^{1024 \\times 1024}$. Which one is faster?\n",
        "\n",
        "\n",
        "[Discussions](https://discuss.d2l.ai/t/421)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "DjzEtZOdBglm",
        "outputId": "b0eff1ba-80fe-4aa5-8e92-fc7edf4bab58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "id": "DjzEtZOdBglm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb955ddf-76ce-4ad5-98d5-554471280c46\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb955ddf-76ce-4ad5-98d5-554471280c46\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving amblyopia_detection.ipynb to amblyopia_detection.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow numpy pandas matplotlib opencv-python scikit-learn"
      ],
      "metadata": {
        "id": "W-qyL7cDB6Pe",
        "outputId": "d87c80c1-60e8-42e7-c1b6-5e2b8e02066c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "W-qyL7cDB6Pe",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "Rs_HbJxOB-Pe"
      },
      "id": "Rs_HbJxOB-Pe",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define image size\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "# Create an \"images\" directory in Colab\n",
        "image_folder = \"/content/images\"\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "# Function to upload images manually\n",
        "def upload_images():\n",
        "    uploaded = files.upload()  # Opens file uploader\n",
        "    for filename in uploaded.keys():\n",
        "        file_path = os.path.join(image_folder, filename)\n",
        "        with open(file_path, \"wb\") as f:\n",
        "            f.write(uploaded[filename])\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []  # Placeholder for labels\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            images.append(img)\n",
        "            labels.append(0)  # Placeholder label\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Upload images manually\n",
        "upload_images()\n",
        "\n",
        "# Load images from dataset\n",
        "X, y = load_images_from_folder(image_folder)\n",
        "\n",
        "# Normalize images\n",
        "X = X / 255.0\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Dataset loaded and split successfully!\")\n"
      ],
      "metadata": {
        "id": "_KrSuxkECC_d",
        "outputId": "6adca612-38ff-4f24-da4c-a6549048d7d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        }
      },
      "id": "_KrSuxkECC_d",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4740b356-3789-41a3-b702-e29b7104b26d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4740b356-3789-41a3-b702-e29b7104b26d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving img22.jpg to img22.jpg\n",
            "Saving img21.jpg to img21.jpg\n",
            "Saving img20.jpg to img20.jpg\n",
            "Saving img19.jpg to img19.jpg\n",
            "Saving img18.jpg to img18.jpg\n",
            "Saving img17.jpg to img17.jpg\n",
            "Saving img16.jpg to img16.jpg\n",
            "Saving img15.jpg to img15.jpg\n",
            "Saving img14.jpg to img14.jpg\n",
            "Saving img13.jpg to img13.jpg\n",
            "Saving img12.jpg to img12.jpg\n",
            "Saving img11.jpg to img11.jpg\n",
            "Saving img10.jpg to img10.jpg\n",
            "Saving img9.jpg to img9.jpg\n",
            "Saving img8.jpg to img8.jpg\n",
            "Saving img7.jpg to img7.jpg\n",
            "Saving img6.jpg to img6.jpg\n",
            "Saving img5.jpg to img5.jpg\n",
            "Saving im5.jpg to im5.jpg\n",
            "Saving img4.jpg to img4.jpg\n",
            "Saving img3.jpg to img3.jpg\n",
            "Saving img2.jpg to img2.jpg\n",
            "Saving img1.jpg to img1.jpg\n",
            "Dataset loaded and split successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply Histogram Equalization\n",
        "    equalized = cv2.equalizeHist(gray)\n",
        "\n",
        "    # Apply Gaussian Blur\n",
        "    blurred = cv2.GaussianBlur(equalized, (3, 3), 0)\n",
        "\n",
        "    # Apply Edge Detection (Canny)\n",
        "    edges = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "    # Convert back to 3-channel format\n",
        "    processed_img = cv2.merge([edges, edges, edges])\n",
        "\n",
        "    return processed_img\n",
        "\n",
        "# Function to load and preprocess images from a folder\n",
        "def load_images_from_folder(folder):\n",
        "    images, labels = [], []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            img = preprocess_image(img)  # Apply preprocessing\n",
        "            images.append(img)\n",
        "            labels.append(0)  # Placeholder label (change based on dataset)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load dataset\n",
        "image_folder = \"images\"  # Modify based on your path\n",
        "X, y = load_images_from_folder(image_folder)\n",
        "\n",
        "# Normalize images\n",
        "X = X / 255.0\n",
        "\n",
        "# Reshape for CNN input\n",
        "X = X.reshape(X.shape[0], 128, 128, 3)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Wc7w6997Ch6V"
      },
      "id": "Wc7w6997Ch6V",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# CNN Model for Feature Extraction\n",
        "model = Sequential([\n",
        "    # First Convolutional Block\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    # Flatten & Fully Connected Layers\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Regularization to prevent overfitting\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display Model Summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "1HUPTz9tD91N",
        "outputId": "68f94a78-80ac-4e73-9caf-9dfced8632fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "id": "1HUPTz9tD91N",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=20)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"ocular_cnn_model.h5\")\n"
      ],
      "metadata": {
        "id": "PdqTJSLxEQ18",
        "outputId": "b91ce9e5-0653-4338-849c-121d29c09c34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PdqTJSLxEQ18",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.2778 - loss: 0.7444 - val_accuracy: 1.0000 - val_loss: 9.5456e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.0747e-07\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771ms/step - accuracy: 1.0000 - loss: 4.9479e-05 - val_accuracy: 1.0000 - val_loss: 1.5192e-10\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706ms/step - accuracy: 1.0000 - loss: 2.1352e-05 - val_accuracy: 1.0000 - val_loss: 2.2088e-13\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4715e-09 - val_accuracy: 1.0000 - val_loss: 3.6304e-16\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698ms/step - accuracy: 1.0000 - loss: 1.3734e-10 - val_accuracy: 1.0000 - val_loss: 7.0649e-19\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721ms/step - accuracy: 1.0000 - loss: 6.2540e-13 - val_accuracy: 1.0000 - val_loss: 1.6875e-21\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9495e-13 - val_accuracy: 1.0000 - val_loss: 5.0718e-24\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3198e-16 - val_accuracy: 1.0000 - val_loss: 1.9662e-26\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789ms/step - accuracy: 1.0000 - loss: 1.3877e-18 - val_accuracy: 1.0000 - val_loss: 9.9570e-29\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947ms/step - accuracy: 1.0000 - loss: 3.3497e-15 - val_accuracy: 1.0000 - val_loss: 6.6341e-31\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.2519e-20 - val_accuracy: 1.0000 - val_loss: 5.8064e-33\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.9724e-22 - val_accuracy: 1.0000 - val_loss: 6.6535e-35\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693ms/step - accuracy: 1.0000 - loss: 9.7116e-25 - val_accuracy: 1.0000 - val_loss: 9.9625e-37\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717ms/step - accuracy: 1.0000 - loss: 1.7327e-23 - val_accuracy: 1.0000 - val_loss: 1.9393e-38\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701ms/step - accuracy: 1.0000 - loss: 5.0587e-20 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683ms/step - accuracy: 1.0000 - loss: 1.2327e-22 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1802e-32 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687ms/step - accuracy: 1.0000 - loss: 9.1889e-25 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706ms/step - accuracy: 1.0000 - loss: 1.3889e-29 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training Performance\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the Model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "2-CAbN_8Ekid",
        "outputId": "6bee6c23-7e5b-488c-aa6f-51b28ee54cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "id": "2-CAbN_8Ekid",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define Image Size\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "# Function to Load and Preprocess Images\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []  # Placeholder for labels\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            images.append(img)\n",
        "            labels.append(0)  # Placeholder label\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Create Image Directory in Colab\n",
        "image_folder = \"images\"\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "# Load Images\n",
        "X, y = load_images_from_folder(image_folder)\n",
        "\n",
        "# Normalize Images\n",
        "X = X / 255.0\n",
        "\n",
        "# Split Dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Apply Augmentation\n",
        "datagen.fit(X_train)\n"
      ],
      "metadata": {
        "id": "tsumntRRFap7"
      },
      "id": "tsumntRRFap7",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display Model Summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "qouzkA2mFtrF",
        "outputId": "283d7d27-e596-48e3-b8fd-7d1a3661a002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "id": "qouzkA2mFtrF",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=10)\n"
      ],
      "metadata": {
        "id": "wsCvbsy3Fxh5",
        "outputId": "74e84a1d-55a6-4447-9d51-97fe622f46a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wsCvbsy3Fxh5",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.2778 - loss: 0.7312 - val_accuracy: 1.0000 - val_loss: 0.0594\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750ms/step - accuracy: 1.0000 - loss: 0.0635 - val_accuracy: 1.0000 - val_loss: 7.0993e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 2.1885e-06\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706ms/step - accuracy: 1.0000 - loss: 2.2108e-04 - val_accuracy: 1.0000 - val_loss: 2.1228e-09\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776ms/step - accuracy: 1.0000 - loss: 2.0752e-10 - val_accuracy: 1.0000 - val_loss: 9.3955e-13\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689ms/step - accuracy: 1.0000 - loss: 5.8187e-07 - val_accuracy: 1.0000 - val_loss: 2.4279e-16\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.2815e-16 - val_accuracy: 1.0000 - val_loss: 4.4842e-20\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687ms/step - accuracy: 1.0000 - loss: 2.3652e-15 - val_accuracy: 1.0000 - val_loss: 7.0224e-24\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745ms/step - accuracy: 1.0000 - loss: 6.2439e-21 - val_accuracy: 1.0000 - val_loss: 1.0698e-27\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729ms/step - accuracy: 1.0000 - loss: 4.8634e-23 - val_accuracy: 1.0000 - val_loss: 1.7681e-31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to Visualize Feature Maps\n",
        "def visualize_feature_maps(model, image):\n",
        "    image = image.reshape(1, 128, 128, 3)  # Ensure correct shape\n",
        "\n",
        "    # Forward pass to initialize the model with input\n",
        "    _ = model.predict(image)\n",
        "\n",
        "    # Extract convolutional layer outputs\n",
        "    layer_outputs = [layer.output for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
        "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "    # Compute activations\n",
        "    activations = activation_model.predict(image)\n",
        "\n",
        "    layer_names = [layer.name for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
        "\n",
        "    for layer_name, activation in zip(layer_names, activations):\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(min(activation.shape[-1], 8)):  # Display up to 8 feature maps\n",
        "            plt.subplot(1, 8, i+1)\n",
        "            plt.imshow(activation[0, :, :, i], cmap='viridis')\n",
        "            plt.axis('off')\n",
        "        plt.suptitle(f\"Feature Maps from Layer: {layer_name}\")\n",
        "        plt.show()\n",
        "\n",
        "# Select an image to visualize\n",
        "test_image = X_test[0]\n",
        "visualize_feature_maps(model, test_image)\n"
      ],
      "metadata": {
        "id": "4LIhOlGqF0MR",
        "outputId": "03c1819b-04ac-40a1-eee1-7ed46db2777d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "id": "4LIhOlGqF0MR",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "The layer sequential_2 has never been called and thus has no defined input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ddff122f7a6d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Select an image to visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mvisualize_feature_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-ddff122f7a6d>\u001b[0m in \u001b[0;36mvisualize_feature_maps\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Extract convolutional layer outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mactivation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Compute activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: The layer sequential_2 has never been called and thus has no defined input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Build the model explicitly**\n",
        "model.build(input_shape=(None, 128, 128, 3))\n"
      ],
      "metadata": {
        "id": "SW_8__ShF5Gz"
      },
      "id": "SW_8__ShF5Gz",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to visualize feature maps\n",
        "def visualize_feature_maps(model, image):\n",
        "    image = image.reshape(1, 128, 128, 3)  # Ensure correct shape\n",
        "\n",
        "    # Forward pass to initialize the model with input\n",
        "    _ = model.predict(image)\n",
        "\n",
        "    # Extract convolutional layer outputs\n",
        "    layer_outputs = [layer.output for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
        "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "    # Compute activations\n",
        "    activations = activation_model.predict(image)\n",
        "\n",
        "    layer_names = [layer.name for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
        "\n",
        "    for layer_name, activation in zip(layer_names, activations):\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(min(activation.shape[-1], 8)):  # Display up to 8 feature maps\n",
        "            plt.subplot(1, 8, i+1)\n",
        "            plt.imshow(activation[0, :, :, i], cmap='viridis')\n",
        "            plt.axis('off')\n",
        "        plt.suptitle(f\"Feature Maps from Layer: {layer_name}\")\n",
        "        plt.show()\n",
        "\n",
        "# Select an image from X_test\n",
        "test_image = X_test[0]\n",
        "visualize_feature_maps(model, test_image)\n"
      ],
      "metadata": {
        "id": "lnqRUduKGMg8",
        "outputId": "fce0cba0-c867-4ccb-a50f-1cd5d24015a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "id": "lnqRUduKGMg8",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "The layer sequential_3 has never been called and thus has no defined input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b030117ed5b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Select an image from X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mvisualize_feature_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-b030117ed5b0>\u001b[0m in \u001b[0;36mvisualize_feature_maps\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Extract convolutional layer outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mactivation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Compute activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: The layer sequential_3 has never been called and thus has no defined input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Fix: Ensure Model is Built**\n",
        "model.build(input_shape=(None, 128, 128, 3))\n",
        "model.summary()  # Check if the model is built correctly\n",
        "\n"
      ],
      "metadata": {
        "id": "TugwyXGBGPU2",
        "outputId": "3948b16f-8aea-4e9c-f69e-7bf45fe4153d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "id": "TugwyXGBGPU2",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dummy forward pass to initialize model\n",
        "dummy_input = np.random.rand(1, 128, 128, 3)\n",
        "_ = model.predict(dummy_input)  # This ensures the model is \"called\" at least once\n"
      ],
      "metadata": {
        "id": "Bc1R04UfGc8y",
        "outputId": "c9b128d8-61f1-4c64-a239-fb039876e5fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Bc1R04UfGc8y",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ZmkSApHGvGa"
      },
      "id": "0ZmkSApHGvGa",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "267u1KXcGxQX"
      },
      "id": "267u1KXcGxQX",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFnLR6n-HBdy"
      },
      "id": "MFnLR6n-HBdy",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HWJyCWHcHNro"
      },
      "id": "HWJyCWHcHNro",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}